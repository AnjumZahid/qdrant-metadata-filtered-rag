{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d02c02cc",
   "metadata": {},
   "source": [
    "**Narrowing search space using meta data filter search, leads to faster retrivel ar scale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install PyMuPDF\n",
    "! pip install langchain-community\n",
    "! pip uninstall camelot -y\n",
    "! pip install \"camelot-py[cv]\"\n",
    "! pip install langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250288c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finance_policy.pdf: 4 chunks created\n",
      "hr_rules.pdf: 3 chunks created\n",
      "it_manual.pdf: 3 chunks created\n",
      "\n",
      "‚úÖ Total chunks created: 10\n",
      "\n",
      "Chunk 1 Metadata: {'source': 'finance_policy.pdf'}\n",
      "Content: Finance Department Policy: ...\n",
      "\n",
      "Chunk 2 Metadata: {'source': 'finance_policy.pdf'}\n",
      "Content: All employees must submit their expense reports by the 5th of each month. ...\n",
      "\n",
      "Chunk 3 Metadata: {'source': 'finance_policy.pdf'}\n",
      "Content: the 5th of each month. ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "PDF_FOLDER = \"./pdfs\"   # folder containing your PDF files\n",
    "CHUNK_SIZE = 75\n",
    "CHUNK_OVERLAP = 25\n",
    "# ----------------------------\n",
    "\n",
    "# Initialize text splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract all text from a PDF file (page by page).\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    doc.close()\n",
    "    return text.strip()\n",
    "\n",
    "def create_chunks_from_pdfs(pdf_folder=PDF_FOLDER):\n",
    "    \"\"\"Create chunks from all PDFs in a folder with only 'source' metadata.\"\"\"\n",
    "    all_chunks = []\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(pdf_folder) if f.lower().endswith(\".pdf\")]\n",
    "    if not pdf_files:\n",
    "        raise FileNotFoundError(f\"No PDFs found in {pdf_folder}\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "        pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "        # Split into chunks\n",
    "        chunks = splitter.split_text(pdf_text)\n",
    "\n",
    "        # Create Document objects with only 'source' metadata\n",
    "        for chunk in chunks:\n",
    "            doc = Document(page_content=chunk, metadata={\"source\": pdf_file})\n",
    "            all_chunks.append(doc)\n",
    "\n",
    "        print(f\"{pdf_file}: {len(chunks)} chunks created\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Total chunks created: {len(all_chunks)}\")\n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "# Example run\n",
    "if __name__ == \"__main__\":\n",
    "    documents = create_chunks_from_pdfs()\n",
    "    # Show sample\n",
    "    for i, doc in enumerate(documents[:3], start=1):\n",
    "        print(f\"\\nChunk {i} Metadata:\", doc.metadata)\n",
    "        print(\"Content:\", doc.page_content[:200].replace(\"\\n\", \" \"), \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bab993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have this list from previous step\n",
    "# documents = create_chunks_from_pdfs()\n",
    "\n",
    "def display_all_chunks(documents):\n",
    "    \"\"\"Display all chunks with metadata and a short content preview.\"\"\"\n",
    "    print(f\"\\nüìÑ Total chunks: {len(documents)}\\n\")\n",
    "    for i, doc in enumerate(documents, start=1):\n",
    "        print(f\"---- Chunk {i} ----\")\n",
    "        print(f\"Source : {doc.metadata.get('source')}\")\n",
    "        print(f\"Content:\\n{doc.page_content.strip()}\\n\")\n",
    "\n",
    "# Example usage\n",
    "\n",
    "documents = create_chunks_from_pdfs()\n",
    "display_all_chunks(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50a7174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Stored 10 chunks with metadata in local Qdrant collection: 'pdf_chunks_store'\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# ‚úÖ Initialize Gemini embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "\n",
    "# ‚úÖ Local Qdrant path and collection\n",
    "qdrant_path = \"./local_qdrant_store\"\n",
    "collection_name = \"pdf_chunks_store\"\n",
    "\n",
    "# ‚úÖ Store chunks locally (not remote)\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    path=qdrant_path,  # ‚úÖ Use 'path' instead of 'location'\n",
    "    collection_name=collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Stored {len(documents)} chunks with metadata in local Qdrant collection: '{collection_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2750a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11532\\3904122061.py:16: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.1.2 and will be removed in 0.5.0. Use `QdrantVectorStore` instead.\n",
      "  vectorstore = Qdrant(\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import Qdrant\n",
    "# from langchain_community.vectorstores import Qdrant\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# ‚úÖ Initialize Gemini embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "\n",
    "# ‚úÖ Connect to the same local folder (read-only mode)\n",
    "# Use 'prefer_grpc=False' to avoid locking conflicts\n",
    "client = QdrantClient(path=\"./local_qdrant_store\", prefer_grpc=False)\n",
    "\n",
    "collection_name = \"pdf_chunks_store\"\n",
    "\n",
    "# ‚úÖ Reconnect to the existing Qdrant collection\n",
    "vectorstore = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d5bfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Filtered Search (source = finance_policy.pdf)\n",
      "‚è±Ô∏è Time taken: 0.7412 seconds\n",
      "\n",
      "Result 1: Reimbursements are processed within 10 working days after approval....\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': 'b695d502daff438c8911b365442eae80', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 2: Finance Department Policy:...\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': '7eb4deb0948942259151416397312767', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 3: the 5th of each month....\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': '8d3df158d3db4d61a52680985b8d6ebf', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 4: All employees must submit their expense reports by the 5th of each month....\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': '4256b750fb994cb19b4508bbc7bf549f', '_collection_name': 'pdf_chunks_store'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query = \"What is the hr leave policy?\"\n",
    "metadata_filter = {\"source\": \"finance_policy.pdf\"}\n",
    "\n",
    "# ‚úÖ Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "results = vectorstore.similarity_search(\n",
    "    query=query,\n",
    "    filter=metadata_filter,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "# ‚úÖ End timer\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüîç Filtered Search (source = {metadata_filter['source']})\")\n",
    "print(f\"‚è±Ô∏è Time taken: {elapsed_time:.4f} seconds\\n\")\n",
    "\n",
    "for i, doc in enumerate(results, start=1):\n",
    "    print(f\"Result {i}: {doc.page_content[:120]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5c2df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Unfiltered Search (across all documents)\n",
      "‚è±Ô∏è Time taken: 0.6614 seconds\n",
      "\n",
      "Result 1: Sick leaves must be reported to HR within 24 hours with a medical note....\n",
      "Metadata: {'source': 'hr_rules.pdf', '_id': 'd037bf5985744cc2a6b1c08334148c7e', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 2: HR Department Guidelines:...\n",
      "Metadata: {'source': 'hr_rules.pdf', '_id': '18fc78e0dd1b454ebd454880ce78c97a', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 3: Every employee is entitled to 14 annual leaves per year....\n",
      "Metadata: {'source': 'hr_rules.pdf', '_id': '61b715e83a474aaea4ad18ab5b065a43', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 4: Reimbursements are processed within 10 working days after approval....\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': 'b695d502daff438c8911b365442eae80', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 5: Finance Department Policy:...\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': '7eb4deb0948942259151416397312767', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 6: the 5th of each month....\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': '8d3df158d3db4d61a52680985b8d6ebf', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 7: All employees must submit their expense reports by the 5th of each month....\n",
      "Metadata: {'source': 'finance_policy.pdf', '_id': '4256b750fb994cb19b4508bbc7bf549f', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 8: IT Department Security Rules: \n",
      "Passwords must be updated every 90 days....\n",
      "Metadata: {'source': 'it_manual.pdf', '_id': 'd4b99e0a96d2460b8f9100900dbfa74c', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 9: All system updates should be completed by Friday each week....\n",
      "Metadata: {'source': 'it_manual.pdf', '_id': 'dbf8745b10fe4fa5a24aca8cf8d2b7f0', '_collection_name': 'pdf_chunks_store'}\n",
      "\n",
      "Result 10: Do not share access credentials with anyone....\n",
      "Metadata: {'source': 'it_manual.pdf', '_id': '7ee6631530394c86bc356ce2ad4412e8', '_collection_name': 'pdf_chunks_store'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query = \"What is the hr leave policy?\"\n",
    "\n",
    "# ‚úÖ Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "results_unfiltered = vectorstore.similarity_search(\n",
    "    query=query,\n",
    "    k=10  # same number as filtered version for fair comparison\n",
    ")\n",
    "\n",
    "# ‚úÖ End timer\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nüîç Unfiltered Search (across all documents)\")\n",
    "print(f\"‚è±Ô∏è Time taken: {elapsed_time:.4f} seconds\\n\")\n",
    "\n",
    "for i, doc in enumerate(results_unfiltered, start=1):\n",
    "    print(f\"Result {i}: {doc.page_content[:120]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
